{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4793d93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 1 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 2 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 3 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 4 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 5 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 6 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 7 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 8 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 9 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 10 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 11 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 12 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 13 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 14 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 15 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 16 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 17 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 18 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 19 Data Loaded: Train=2357, Test=590\n",
      "✅ Client 20 Data Loaded: Train=2357, Test=590\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define dataset path\n",
    "dataset_path = \"C:\\\\Users\\\\USER\\\\Downloads\\\\Medical Minist Dataset\"\n",
    "\n",
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "full_dataset = datasets.ImageFolder(root=dataset_path)\n",
    "\n",
    "# Organize data by class\n",
    "class_indices = defaultdict(list)\n",
    "for idx, (_, label) in enumerate(full_dataset.samples):\n",
    "    class_indices[label].append(idx)\n",
    "\n",
    "# Ensure stratified sampling\n",
    "num_clients = 20\n",
    "train_ratio = 0.8  # 80% training, 20% testing\n",
    "\n",
    "client_indices = [[] for _ in range(num_clients)]\n",
    "\n",
    "# Distribute data across clients while keeping class balance\n",
    "for label, indices in class_indices.items():\n",
    "    np.random.shuffle(indices)\n",
    "    splits = np.array_split(indices, num_clients)\n",
    "   \n",
    "    for client_id, split in enumerate(splits):\n",
    "        client_indices[client_id].extend(split.tolist())\n",
    "\n",
    "# Ensure exact same number of samples per client\n",
    "min_train_size = min(len(indices) * train_ratio for indices in client_indices)\n",
    "min_test_size = min(len(indices) * (1 - train_ratio) for indices in client_indices)\n",
    "\n",
    "for i in range(num_clients):\n",
    "    np.random.shuffle(client_indices[i])\n",
    "    client_indices[i] = client_indices[i][:int(min_train_size + min_test_size)]\n",
    "\n",
    "# Custom dataset wrapper to apply transformations\n",
    "class CustomSubset(Dataset):\n",
    "    def __init__(self, dataset, indices, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        self.transform = transform\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[self.indices[idx]]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "# Split each client's data into training and testing sets\n",
    "train_loaders, test_loaders = [], []\n",
    "train_sizes, test_sizes = [], []\n",
    "\n",
    "batch_size = 32\n",
    "for i, indices in enumerate(client_indices):\n",
    "    split_idx = int(len(indices) * train_ratio)\n",
    "   \n",
    "    train_indices = indices[:split_idx]\n",
    "    test_indices = indices[split_idx:]\n",
    "\n",
    "    train_dataset = CustomSubset(full_dataset, train_indices, transform=train_transform)\n",
    "    test_dataset = CustomSubset(full_dataset, test_indices, transform=test_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "    train_loaders.append(train_loader)\n",
    "    test_loaders.append(test_loader)\n",
    "\n",
    "    train_sizes.append(len(train_dataset))\n",
    "    test_sizes.append(len(test_dataset))\n",
    "\n",
    "    print(f\"✅ Client {i+1} Data Loaded: Train={len(train_dataset)}, Test={len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d90dfb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 1: 100%|██████████| 74/74 [04:01<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 1 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 1: 100%|██████████| 19/19 [01:02<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 1 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 2: 100%|██████████| 74/74 [03:58<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 2 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 2: 100%|██████████| 19/19 [00:54<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 2 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 3: 100%|██████████| 74/74 [03:47<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 3 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 3: 100%|██████████| 19/19 [00:53<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 3 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 4: 100%|██████████| 74/74 [03:47<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 4 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 4: 100%|██████████| 19/19 [00:53<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 4 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 5: 100%|██████████| 74/74 [03:41<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 5 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 5: 100%|██████████| 19/19 [00:52<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 5 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 6: 100%|██████████| 74/74 [03:45<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 6 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 6: 100%|██████████| 19/19 [00:55<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 6 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 7: 100%|██████████| 74/74 [03:38<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 7 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 7: 100%|██████████| 19/19 [00:53<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 7 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 8: 100%|██████████| 74/74 [03:39<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 8 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 8: 100%|██████████| 19/19 [00:50<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 8 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 9: 100%|██████████| 74/74 [03:41<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 9 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 9: 100%|██████████| 19/19 [00:54<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 9 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 10: 100%|██████████| 74/74 [03:42<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 10 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 10: 100%|██████████| 19/19 [00:52<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 10 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 11: 100%|██████████| 74/74 [03:40<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 11 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 11: 100%|██████████| 19/19 [00:52<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 11 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 12: 100%|██████████| 74/74 [03:41<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 12 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 12: 100%|██████████| 19/19 [00:50<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 12 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 13: 100%|██████████| 74/74 [03:38<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 13 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 13: 100%|██████████| 19/19 [00:53<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 13 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 14: 100%|██████████| 74/74 [03:37<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 14 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 14: 100%|██████████| 19/19 [00:52<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 14 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 15: 100%|██████████| 74/74 [03:38<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 15 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 15: 100%|██████████| 19/19 [00:51<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 15 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 16: 100%|██████████| 74/74 [03:37<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 16 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 16: 100%|██████████| 19/19 [00:51<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 16 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 17: 100%|██████████| 74/74 [03:42<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 17 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 17: 100%|██████████| 19/19 [00:52<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 17 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 18: 100%|██████████| 74/74 [03:45<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 18 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 18: 100%|██████████| 19/19 [00:51<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 18 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 19: 100%|██████████| 74/74 [03:43<00:00,  3.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 19 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 19: 100%|██████████| 19/19 [00:52<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 19 test Features Extracted: (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train Features for Client 20: 100%|██████████| 74/74 [03:39<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 20 train Features Extracted: (2357, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting test Features for Client 20: 100%|██████████| 19/19 [00:52<00:00,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client 20 test Features Extracted: (590, 512)\n",
      "\n",
      "✅ Feature Extraction Complete!\n",
      "Client 1: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 2: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 3: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 4: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 5: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 6: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 7: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 8: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 9: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 10: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 11: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 12: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 13: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 14: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 15: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 16: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 17: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 18: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 19: Train Shape = (2357, 512), Test Shape = (590, 512)\n",
      "Client 20: Train Shape = (2357, 512), Test Shape = (590, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pretrained ResNet-18 (WITHOUT last layers) for consistency\n",
    "resnet_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)  \n",
    "resnet_model = torch.nn.Sequential(*list(resnet_model.children())[:-2])  # Consistent feature extractor\n",
    "resnet_model.eval().to(device)\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_features(data_loader, dataset_type, client_id, model):\n",
    "    feature_list, labels_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader, desc=f\"Extracting {dataset_type} Features for Client {client_id}\"):\n",
    "            images = images.to(device)\n",
    "            features = model(images)  # Extract features\n",
    "            features = features.mean(dim=[2, 3])  # Global Average Pooling\n",
    "            feature_list.append(features.cpu().numpy())\n",
    "            labels_list.append(labels.numpy())\n",
    "\n",
    "    features_array = np.vstack(feature_list)\n",
    "    labels_array = np.concatenate(labels_list)\n",
    "\n",
    "    # Save extracted features and labels\n",
    "    np.save(f\"client_{client_id}_{dataset_type}_features.npy\", features_array)\n",
    "    np.save(f\"client_{client_id}_{dataset_type}_labels.npy\", labels_array)\n",
    "\n",
    "    print(f\"✅ Client {client_id} {dataset_type} Features Extracted: {features_array.shape}\")\n",
    "\n",
    "    return features_array, labels_array\n",
    "\n",
    "# Extract features for clients\n",
    "client_train_features, client_test_features = [], []\n",
    "client_train_labels, client_test_labels = [], []\n",
    "\n",
    "for i, (train_loader, test_loader) in enumerate(zip(train_loaders, test_loaders)):\n",
    "    train_features, train_labels = extract_features(train_loader, \"train\", i+1, resnet_model)\n",
    "    test_features, test_labels = extract_features(test_loader, \"test\", i+1, resnet_model)  # Using the same model\n",
    "\n",
    "    client_train_features.append(train_features)\n",
    "    client_train_labels.append(train_labels)\n",
    "    client_test_features.append(test_features)\n",
    "    client_test_labels.append(test_labels)\n",
    "\n",
    "print(\"\\n✅ Feature Extraction Complete!\")\n",
    "\n",
    "# Debugging Feature Shapes\n",
    "for i, features in enumerate(client_train_features):\n",
    "    print(f\"Client {i+1}: Train Shape = {features.shape}, Test Shape = {client_test_features[i].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fcc0a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Training Data for Client 1:\n",
      "📊 Client 1 Class Distribution: {1: 342, 3: 397, 0: 412, 4: 410, 2: 398, 5: 398}\n",
      "🔹 Training Data for Client 2:\n",
      "📊 Client 2 Class Distribution: {4: 406, 3: 407, 2: 404, 5: 394, 0: 407, 1: 339}\n",
      "🔹 Training Data for Client 3:\n",
      "📊 Client 3 Class Distribution: {4: 383, 5: 395, 2: 416, 0: 410, 1: 369, 3: 384}\n",
      "🔹 Training Data for Client 4:\n",
      "📊 Client 4 Class Distribution: {1: 341, 4: 402, 2: 418, 5: 407, 0: 398, 3: 391}\n",
      "🔹 Training Data for Client 5:\n",
      "📊 Client 5 Class Distribution: {0: 399, 5: 406, 1: 355, 2: 397, 3: 393, 4: 407}\n",
      "🔹 Training Data for Client 6:\n",
      "📊 Client 6 Class Distribution: {3: 393, 5: 407, 2: 403, 0: 405, 4: 401, 1: 348}\n",
      "🔹 Training Data for Client 7:\n",
      "📊 Client 7 Class Distribution: {5: 400, 0: 401, 3: 401, 1: 362, 4: 403, 2: 390}\n",
      "🔹 Training Data for Client 8:\n",
      "📊 Client 8 Class Distribution: {0: 394, 3: 408, 4: 403, 2: 383, 1: 357, 5: 412}\n",
      "🔹 Training Data for Client 9:\n",
      "📊 Client 9 Class Distribution: {4: 406, 1: 359, 2: 399, 3: 395, 0: 394, 5: 404}\n",
      "🔹 Training Data for Client 10:\n",
      "📊 Client 10 Class Distribution: {3: 396, 1: 359, 0: 399, 5: 403, 2: 401, 4: 399}\n",
      "🔹 Training Data for Client 11:\n",
      "📊 Client 11 Class Distribution: {3: 377, 2: 415, 4: 396, 1: 365, 5: 401, 0: 403}\n",
      "🔹 Training Data for Client 12:\n",
      "📊 Client 12 Class Distribution: {2: 404, 1: 344, 4: 407, 3: 409, 0: 395, 5: 398}\n",
      "🔹 Training Data for Client 13:\n",
      "📊 Client 13 Class Distribution: {4: 408, 0: 414, 1: 341, 5: 393, 2: 408, 3: 393}\n",
      "🔹 Training Data for Client 14:\n",
      "📊 Client 14 Class Distribution: {4: 416, 3: 392, 1: 365, 2: 393, 0: 407, 5: 384}\n",
      "🔹 Training Data for Client 15:\n",
      "📊 Client 15 Class Distribution: {0: 404, 5: 402, 2: 410, 4: 391, 3: 400, 1: 350}\n",
      "🔹 Training Data for Client 16:\n",
      "📊 Client 16 Class Distribution: {1: 360, 0: 392, 5: 393, 3: 405, 2: 402, 4: 405}\n",
      "🔹 Training Data for Client 17:\n",
      "📊 Client 17 Class Distribution: {0: 393, 5: 399, 4: 403, 3: 390, 2: 403, 1: 369}\n",
      "🔹 Training Data for Client 18:\n",
      "📊 Client 18 Class Distribution: {0: 407, 2: 403, 4: 408, 5: 385, 1: 353, 3: 401}\n",
      "🔹 Training Data for Client 19:\n",
      "📊 Client 19 Class Distribution: {4: 398, 5: 407, 3: 392, 1: 366, 0: 402, 2: 392}\n",
      "🔹 Training Data for Client 20:\n",
      "📊 Client 20 Class Distribution: {3: 396, 4: 400, 0: 399, 5: 404, 1: 355, 2: 403}\n",
      "🔹 Testing Data for Client 1:\n",
      "📊 Client 1 Class Distribution: {1: 105, 5: 102, 2: 102, 4: 90, 0: 88, 3: 103}\n",
      "🔹 Testing Data for Client 2:\n",
      "📊 Client 2 Class Distribution: {4: 94, 5: 106, 1: 109, 0: 93, 3: 93, 2: 95}\n",
      "🔹 Testing Data for Client 3:\n",
      "📊 Client 3 Class Distribution: {0: 90, 1: 78, 3: 116, 4: 117, 5: 105, 2: 84}\n",
      "🔹 Testing Data for Client 4:\n",
      "📊 Client 4 Class Distribution: {1: 107, 5: 92, 2: 82, 3: 109, 0: 102, 4: 98}\n",
      "🔹 Testing Data for Client 5:\n",
      "📊 Client 5 Class Distribution: {1: 92, 5: 94, 3: 107, 2: 103, 4: 93, 0: 101}\n",
      "🔹 Testing Data for Client 6:\n",
      "📊 Client 6 Class Distribution: {5: 92, 2: 97, 1: 100, 4: 99, 3: 107, 0: 95}\n",
      "🔹 Testing Data for Client 7:\n",
      "📊 Client 7 Class Distribution: {0: 99, 4: 96, 5: 100, 3: 99, 1: 86, 2: 110}\n",
      "🔹 Testing Data for Client 8:\n",
      "📊 Client 8 Class Distribution: {5: 88, 0: 106, 3: 92, 1: 91, 4: 96, 2: 117}\n",
      "🔹 Testing Data for Client 9:\n",
      "📊 Client 9 Class Distribution: {4: 94, 0: 105, 3: 105, 5: 96, 2: 101, 1: 89}\n",
      "🔹 Testing Data for Client 10:\n",
      "📊 Client 10 Class Distribution: {3: 104, 4: 101, 1: 89, 2: 98, 0: 101, 5: 97}\n",
      "🔹 Testing Data for Client 11:\n",
      "📊 Client 11 Class Distribution: {4: 104, 2: 85, 0: 97, 5: 99, 3: 122, 1: 83}\n",
      "🔹 Testing Data for Client 12:\n",
      "📊 Client 12 Class Distribution: {5: 102, 2: 96, 0: 105, 1: 104, 3: 91, 4: 92}\n",
      "🔹 Testing Data for Client 13:\n",
      "📊 Client 13 Class Distribution: {2: 92, 1: 107, 3: 107, 0: 85, 4: 92, 5: 107}\n",
      "🔹 Testing Data for Client 14:\n",
      "📊 Client 14 Class Distribution: {5: 116, 4: 84, 2: 107, 3: 107, 0: 93, 1: 83}\n",
      "🔹 Testing Data for Client 15:\n",
      "📊 Client 15 Class Distribution: {2: 90, 5: 98, 4: 109, 0: 96, 1: 97, 3: 100}\n",
      "🔹 Testing Data for Client 16:\n",
      "📊 Client 16 Class Distribution: {0: 108, 4: 95, 1: 87, 5: 107, 3: 95, 2: 98}\n",
      "🔹 Testing Data for Client 17:\n",
      "📊 Client 17 Class Distribution: {2: 97, 5: 101, 0: 107, 3: 110, 4: 97, 1: 78}\n",
      "🔹 Testing Data for Client 18:\n",
      "📊 Client 18 Class Distribution: {5: 115, 0: 93, 2: 97, 4: 92, 1: 94, 3: 99}\n",
      "🔹 Testing Data for Client 19:\n",
      "📊 Client 19 Class Distribution: {1: 81, 4: 102, 3: 108, 2: 108, 5: 93, 0: 98}\n",
      "🔹 Testing Data for Client 20:\n",
      "📊 Client 20 Class Distribution: {5: 96, 3: 104, 2: 97, 0: 101, 1: 92, 4: 100}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_class_distribution(dataset, client_id):\n",
    "    labels = [label for _, label in dataset.dataset.samples]  # Extract all labels from original dataset\n",
    "    label_counts = Counter([labels[idx] for idx in dataset.indices])  # Count labels for this subset\n",
    "    print(f\"📊 Client {client_id} Class Distribution: {dict(label_counts)}\")\n",
    "\n",
    "# Print for both training and testing datasets\n",
    "for i, dataset in enumerate(train_loaders):  # Change to `train_loaders`\n",
    "    print(f\"🔹 Training Data for Client {i+1}:\")\n",
    "    print_class_distribution(dataset.dataset, i+1)\n",
    "\n",
    "for i, dataset in enumerate(test_loaders):  # Change to `test_loaders`\n",
    "    print(f\"🔹 Testing Data for Client {i+1}:\")\n",
    "    print_class_distribution(dataset.dataset, i+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
